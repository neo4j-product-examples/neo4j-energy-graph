{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Create Energy Graph\n",
    "\n",
    "This notebook will create a graph representing an energy grid with customer installations.\n",
    "\n",
    "It is split into two sections\n",
    "\n",
    "1. __Structured Source__: Tabular data. Ingestion is done with Cypher query templates (ordinary ETL)\n",
    "2. __Unstructured Source__: Text data. In this case maintenance records. In estion involves an LLM powered entity extraction step prior to loading with a Cypher query templates"
   ],
   "id": "5e2a9a893f992e18"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Structured Source",
   "id": "98c93e65ea4f7394"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "from neo4j import GraphDatabase\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from getpass import getpass\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# get credentials\n",
    "load_dotenv('target-db.env', override=True)\n",
    "\n",
    "uri = os.getenv('NEO4J_URI')\n",
    "username = os.getenv('NEO4J_USERNAME')\n",
    "password = os.getenv('NEO4J_PASSWORD')\n",
    "\n",
    "if not uri:\n",
    "  uri = getpass(\"Please enter your Neo4j URI: \")\n",
    "if not username:\n",
    "  username = getpass(\"Please enter your Neo4j username: \")\n",
    "if not password:\n",
    "  password = getpass(\"Please enter your Neo4j password: \")\n",
    "\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from neo4j import RoutingControl\n",
    "\n",
    "#create uniqueness constraint if not exists\n",
    "driver.execute_query(\n",
    "    'CREATE CONSTRAINT IF NOT EXISTS FOR (n:Generator) REQUIRE (n.id) IS NODE KEY',\n",
    "    #database_=DATABASE,\n",
    "    routing_=RoutingControl.WRITE\n",
    ")\n",
    "\n",
    "driver.execute_query(\n",
    "    'CREATE CONSTRAINT IF NOT EXISTS FOR (n:Bus) REQUIRE (n.id) IS NODE KEY',\n",
    "    #database_=DATABASE,\n",
    "    routing_=RoutingControl.WRITE\n",
    ")\n",
    "\n",
    "driver.execute_query(\n",
    "    'CREATE CONSTRAINT IF NOT EXISTS FOR (n:Transformer) REQUIRE (n.id) IS NODE KEY',\n",
    "    #database_=DATABASE,\n",
    "    routing_=RoutingControl.WRITE\n",
    ")\n",
    "\n",
    "driver.execute_query(\n",
    "    'CREATE CONSTRAINT IF NOT EXISTS FOR (n:Link) REQUIRE (n.id) IS NODE KEY',\n",
    "    #database_=DATABASE,\n",
    "    routing_=RoutingControl.WRITE\n",
    ")\n",
    "\n",
    "driver.execute_query(\n",
    "    'CREATE CONSTRAINT IF NOT EXISTS FOR (n:Station) REQUIRE (n.id) IS NODE KEY',\n",
    "    #database_=DATABASE,\n",
    "    routing_=RoutingControl.WRITE\n",
    ")\n",
    "\n",
    "\n",
    "driver.execute_query(\n",
    "    'CREATE CONSTRAINT IF NOT EXISTS FOR (n:Customer) REQUIRE (n.id) IS NODE KEY',\n",
    "    #database_=DATABASE,\n",
    "    routing_=RoutingControl.WRITE\n",
    ")\n",
    "\n",
    "driver.execute_query(\n",
    "    'CREATE CONSTRAINT IF NOT EXISTS FOR (n:Installation) REQUIRE (n.id) IS NODE KEY',\n",
    "    #database_=DATABASE,\n",
    "    routing_=RoutingControl.WRITE\n",
    ")\n",
    "\n",
    "driver.execute_query(\n",
    "    'CREATE CONSTRAINT IF NOT EXISTS FOR (n:Region) REQUIRE (n.id) IS NODE KEY',\n",
    "    #database_=DATABASE,\n",
    "    routing_=RoutingControl.WRITE\n",
    ")\n",
    "\n",
    "driver.execute_query(\n",
    "    'CREATE CONSTRAINT IF NOT EXISTS FOR (n:Consumption) REQUIRE (n.id) IS NODE KEY',\n",
    "    #database_=DATABASE,\n",
    "    routing_=RoutingControl.WRITE\n",
    ")\n",
    "\n",
    "driver.execute_query(\n",
    "    'CREATE CONSTRAINT IF NOT EXISTS FOR (n:Ticket) REQUIRE (n.ticketNumber) IS NODE KEY',\n",
    "    #database_=DATABASE,\n",
    "    routing_=RoutingControl.WRITE\n",
    ")\n",
    "\n",
    "driver.execute_query(\n",
    "    'CREATE CONSTRAINT IF NOT EXISTS FOR (n:MaintenanceRecord) REQUIRE (n.id) IS NODE KEY',\n",
    "    #database_=DATABASE,\n",
    "    routing_=RoutingControl.WRITE\n",
    ")\n",
    "\n",
    "driver.execute_query(\n",
    "    'CREATE CONSTRAINT IF NOT EXISTS FOR (n:Alert) REQUIRE (n.id) IS NODE KEY',\n",
    "    #database_=DATABASE,\n",
    "    routing_=RoutingControl.WRITE\n",
    ")"
   ],
   "id": "84d2b5656245a31c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_dir = \"source-data\"\n",
    "# helper function\n",
    "def chunks(xs, n=1_000):\n",
    "    n = max(1, n)\n",
    "    return [xs[i:i + n] for i in range(0, len(xs), n)]"
   ],
   "id": "7cacfdbe8c9f6713",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from neo4j import RoutingControl\n",
    "\n",
    "generator_df = pd.read_csv(os.path.join(data_dir,'generators.csv'))\n",
    "\n",
    "for records in chunks(generator_df.to_dict(orient='records')):\n",
    "    res = generator_df = driver.execute_query(\"\"\"\n",
    "      UNWIND $records as rec\n",
    "      MERGE (g:Generator {id:rec.ID})\n",
    "      MERGE (b:Bus {id:rec.BUS_ID})\n",
    "      MERGE (g)-[r:CONNECTED]->(b)\n",
    "      SET\n",
    "        g.capacity = rec.CAPACITY,\n",
    "        g.category = rec.CATEGORY,\n",
    "        g.geometry = point({latitude: rec.LATITUDE, longitude: rec.LONGITUDE}),\n",
    "        g.mb_symbol = rec.MB_SYMBOL,\n",
    "        g.name_eng = rec.NAME_ENG,\n",
    "        g.name_nat = rec.NAME_NAT,\n",
    "        g.symbol = rec.SYMBOL,\n",
    "        g.tso = rec.TSO,\n",
    "        g.visible = rec.VISIBLE\n",
    "      RETURN count(rec) AS records_upserted\n",
    "    \"\"\",\n",
    "        #database_=DATABASE,\n",
    "        routing_=RoutingControl.WRITE,\n",
    "        result_transformer_= lambda r: r.data(),\n",
    "        records = records\n",
    "    )\n",
    "    print(res)"
   ],
   "id": "9cc6b0ab8273207c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "bus_df = pd.read_csv(os.path.join(data_dir,'buses.csv'))\n",
    "\n",
    "for records in chunks(bus_df.to_dict(orient='records')):\n",
    "    res = driver.execute_query(\"\"\"\n",
    "      UNWIND $records AS rec\n",
    "      MERGE (b:Bus {id: rec.ID})\n",
    "      MERGE (s:Station {id: rec.STATION_ID})\n",
    "      MERGE (b)-[:IN_STATION]->(s)\n",
    "      SET\n",
    "        b.category = rec.CATEGORY,\n",
    "        b.geometry = point({latitude: rec.LATITUDE, longitude: rec.LONGITUDE}),\n",
    "        b.mb_symbol = rec.MB_SYMBOL,\n",
    "        b.name_eng = rec.NAME_ENG,\n",
    "        b.name_nat = rec.NAME_NAT,\n",
    "        b.symbol = rec.SYMBOL,\n",
    "        b.tso = rec.TSO,\n",
    "        b.visible = rec.VISIBLE,\n",
    "        b.voltage = rec.VOLTAGE\n",
    "      RETURN count(rec) AS records_upserted\n",
    "    \"\"\", routing_=RoutingControl.WRITE, result_transformer_=lambda r: r.data(), records=records)\n",
    "    print(res)"
   ],
   "id": "4ba47c64be68490a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "transformer_df = pd.read_csv(os.path.join(data_dir,'transformers.csv'))\n",
    "\n",
    "for records in chunks(transformer_df.to_dict(orient='records')):\n",
    "    res = driver.execute_query(\"\"\"\n",
    "      UNWIND $records AS rec\n",
    "      MERGE (t:Transformer {id: rec.ID})\n",
    "      MERGE (b:Bus {id: rec.BUS_ID})\n",
    "      MERGE (t)-[:CONNECTED]->(b)\n",
    "      SET\n",
    "        t.dst_dc = rec.DST_DC,\n",
    "        t.dst_voltage = rec.DST_VOLTAGE,\n",
    "        t.geometry = point({latitude: rec.LATITUDE, longitude: rec.LONGITUDE}),\n",
    "        t.src_dc = rec.SRC_DC,\n",
    "        t.src_voltage = rec.SRC_VOLTAGE,\n",
    "        t.symbol = rec.SYMBOL\n",
    "      RETURN count(rec) AS records_upserted\n",
    "    \"\"\", routing_=RoutingControl.WRITE, result_transformer_=lambda r: r.data(), records=records)\n",
    "    print(res)"
   ],
   "id": "c345c529a8ed45b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "link_df = pd.read_csv(os.path.join(data_dir,'links.csv'))\n",
    "\n",
    "for records in chunks(link_df.to_dict(orient='records')):\n",
    "    res = driver.execute_query(\"\"\"\n",
    "      UNWIND $records AS rec\n",
    "      MERGE (l:Link {id: rec.ID})\n",
    "      MERGE (b:Bus {id: rec.BUS_ID})\n",
    "      MERGE (l)-[:CONNECTED]->(b)\n",
    "      SET\n",
    "        l.circuits = rec.CIRCUITS,\n",
    "        l.dc = rec.DC,\n",
    "        l.length_m = rec.LENGTH_M,\n",
    "        l.shape_leng = rec.SHAPE_LENG,\n",
    "        l.symbol = rec.SYMBOL,\n",
    "        l.t9_code = rec.T9_CODE,\n",
    "        l.underground = rec.UNDERGROUND,\n",
    "        l.visible = rec.VISIBLE,\n",
    "        l.voltage = rec.VOLTAGE\n",
    "      RETURN count(rec) AS records_upserted\n",
    "    \"\"\", routing_=RoutingControl.WRITE, result_transformer_=lambda r: r.data(), records=records)\n",
    "    print(res)"
   ],
   "id": "fa27ea49d69401e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "station_df = pd.read_csv(os.path.join(data_dir,'stations.csv'))\n",
    "\n",
    "for records in chunks(station_df.to_dict(orient='records')):\n",
    "    res = driver.execute_query(\"\"\"\n",
    "      UNWIND $records AS rec\n",
    "      MERGE (s:Station {id: rec.ID})\n",
    "      SET\n",
    "        s.name_eng = rec.NAME_ENG,\n",
    "        s.geometry = point({latitude: rec.LATITUDE, longitude: rec.LONGITUDE})\n",
    "      RETURN count(rec) AS records_upserted\n",
    "    \"\"\", routing_=RoutingControl.WRITE, result_transformer_=lambda r: r.data(), records=records)\n",
    "    print(res)\n"
   ],
   "id": "735e927e2b72dcbb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "customer_df = pd.read_csv(os.path.join(data_dir,'customers.csv'))\n",
    "\n",
    "for records in chunks(customer_df.to_dict(orient='records')):\n",
    "    res = driver.execute_query(\"\"\"\n",
    "      UNWIND $records AS rec\n",
    "      MERGE (c:Customer {id: rec.ID})\n",
    "      SET\n",
    "        c.name = rec.NAME,\n",
    "        c.type = rec.TYPE\n",
    "      RETURN count(rec) AS records_upserted\n",
    "    \"\"\", routing_=RoutingControl.WRITE, result_transformer_=lambda r: r.data(), records=records)\n",
    "    print(res)\n"
   ],
   "id": "e8b67b23c8f788eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "installation_df = pd.read_csv(os.path.join(data_dir,'installations.csv'))\n",
    "\n",
    "for records in chunks(installation_df.to_dict(orient='records')):\n",
    "    res = driver.execute_query(\"\"\"\n",
    "      UNWIND $records AS rec\n",
    "      MERGE (i:Installation {id: rec.ID})\n",
    "      SET\n",
    "        i.installationDate = rec.INSTALLATIONDATE,\n",
    "        i.nome = rec.NOME,\n",
    "        i.type = rec.TYPE\n",
    "      RETURN count(rec) AS records_upserted\n",
    "    \"\"\", routing_=RoutingControl.WRITE, result_transformer_=lambda r: r.data(), records=records)\n",
    "    print(res)\n",
    "\n",
    "# Due to data quality issues a minority of installations are missing customers, links, and/or region. We work around for now\n",
    "for records in chunks(installation_df[~installation_df.LINK_ID.isna()].to_dict(orient='records')):\n",
    "    res = driver.execute_query(\"\"\"\n",
    "      UNWIND $records AS rec\n",
    "      MERGE (i:Installation {id: rec.ID})\n",
    "      MERGE (l:Link {id: rec.LINK_ID})\n",
    "      MERGE (l)-[:LINK_HAS_INSTALLATION]->(i)\n",
    "      RETURN count(rec) AS records_upserted\n",
    "    \"\"\", routing_=RoutingControl.WRITE, result_transformer_=lambda r: r.data(), records=records)\n",
    "    print(res)\n",
    "\n",
    "for records in chunks(installation_df[~installation_df.CUSTOMER_ID.isna()].to_dict(orient='records')):\n",
    "    res = driver.execute_query(\"\"\"\n",
    "      UNWIND $records AS rec\n",
    "      MERGE (i:Installation {id: rec.ID})\n",
    "      MERGE (c:Customer {id: rec.CUSTOMER_ID})\n",
    "      MERGE (c)-[:CUSTOMER_HAS_INSTALLATION]->(i)\n",
    "      RETURN count(rec) AS records_upserted\n",
    "    \"\"\", routing_=RoutingControl.WRITE, result_transformer_=lambda r: r.data(), records=records)\n",
    "    print(res)\n",
    "\n",
    "for records in chunks(installation_df[~installation_df.REGION_ID.isna()].to_dict(orient='records')):\n",
    "    res = driver.execute_query(\"\"\"\n",
    "      UNWIND $records AS rec\n",
    "      MERGE (i:Installation {id: rec.ID})\n",
    "      MERGE (r:Region {id: rec.REGION_ID})\n",
    "      MERGE (i)-[:INSTALL_HAS_REGION]->(r)\n",
    "      RETURN count(rec) AS records_upserted\n",
    "    \"\"\", routing_=RoutingControl.WRITE, result_transformer_=lambda r: r.data(), records=records)\n",
    "    print(res)\n"
   ],
   "id": "7f0718e80ae1fbdb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "region_df = pd.read_csv(os.path.join(data_dir,'regions.csv'))\n",
    "\n",
    "for records in chunks(region_df.to_dict(orient='records')):\n",
    "    res = driver.execute_query(\"\"\"\n",
    "      UNWIND $records AS rec\n",
    "      MERGE (r:Region {id: rec.ID})\n",
    "      SET r.name = rec.NAME\n",
    "      RETURN count(rec) AS records_upserted\n",
    "    \"\"\", routing_=RoutingControl.WRITE, result_transformer_=lambda r: r.data(), records=records)\n",
    "    print(res)"
   ],
   "id": "1d13624cd77e00de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "consumption_df = pd.read_csv(os.path.join(data_dir,'consumption_logs.csv'))\n",
    "\n",
    "for records in chunks(consumption_df.to_dict(orient='records')):\n",
    "    res = driver.execute_query(\"\"\"\n",
    "      UNWIND $records AS rec\n",
    "      MERGE (c:Consumption {id: rec.ID})\n",
    "      MERGE (i:Installation {id: rec.INSTALLATION_ID})\n",
    "      MERGE (i)-[:INSTALL_HAS_CONSUMPTION]->(c)\n",
    "      SET\n",
    "        c.seqId = rec.SEQ_ID,\n",
    "        c.referenceDate = rec.REFERENCEDATE,\n",
    "        c.quantity = rec.QUANTIDADE,\n",
    "        c.consumptionValue = rec.CONSUMPTIONVALUE,\n",
    "        c.invoiceValue = rec.INVOICEVALUE,\n",
    "        c.newConsumptionValue = rec.NEWCONSUMPTIONVALUE\n",
    "      //add NEXT relationships\n",
    "      WITH c,i, rec\n",
    "      MATCH (i)-[:INSTALL_HAS_CONSUMPTION]->(c_next:Consumption {seqId: c.seqId + 1})\n",
    "      MERGE (c)-[:NEXT]->(c_next)\n",
    "      RETURN count(rec) AS records_upserted\n",
    "    \"\"\", routing_=RoutingControl.WRITE, result_transformer_=lambda r: r.data(), records=records)\n",
    "    print(res)\n",
    "\n",
    "# First\n",
    "res = driver.execute_query(\"\"\"\n",
    "MATCH(i:Installation)-[:INSTALL_HAS_CONSUMPTION]->(c)\n",
    "WHERE COUNT{()-[:NEXT]->(c)} = 0\n",
    "MERGE (i)-[r:FIRST]->(c)\n",
    "RETURN count(r) AS relationships_written\n",
    "\"\"\", routing_=RoutingControl.WRITE, result_transformer_=lambda r: r.data())\n",
    "print(res)\n",
    "\n",
    "# Last\n",
    "res = driver.execute_query(\"\"\"\n",
    "MATCH(i:Installation)-[:INSTALL_HAS_CONSUMPTION]->(c)\n",
    "WHERE COUNT{(c)-[:NEXT]->()} = 0\n",
    "MERGE (i)-[r:LAST]->(c)\n",
    "RETURN count(r) AS relationships_written\n",
    "\"\"\", routing_=RoutingControl.WRITE, result_transformer_=lambda r: r.data())\n",
    "print(res)"
   ],
   "id": "a116e4ce36cd2eb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ticket_df = pd.read_csv(os.path.join(data_dir,'tickets.csv'))\n",
    "\n",
    "for records in chunks(ticket_df.to_dict(orient='records')):\n",
    "    res = driver.execute_query(\"\"\"\n",
    "      UNWIND $records AS rec\n",
    "      MERGE (t:Ticket {ticketNumber: rec.TICKETNUMBER})\n",
    "      MERGE (c:Customer {id: rec.CUSTOMER_ID})\n",
    "      MERGE (c)-[:CREATED_TICKET]->(t)\n",
    "      SET\n",
    "        t.createdDate = rec.CREATEDATE,\n",
    "        t.resolutionDate = rec.RESOLUTIONDATE,\n",
    "        t.severity = rec.SEVERITY,\n",
    "        t.status = rec.STATUS\n",
    "      RETURN count(rec) AS records_upserted\n",
    "    \"\"\", routing_=RoutingControl.WRITE, result_transformer_=lambda r: r.data(), records=records)\n",
    "    print(res)"
   ],
   "id": "4a535106f17011a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "alert_df = pd.read_csv(os.path.join(data_dir,'alerts.csv'))\n",
    "\n",
    "for records in chunks(alert_df.to_dict(orient='records')):\n",
    "    res = driver.execute_query(\"\"\"\n",
    "      UNWIND $records AS rec\n",
    "      MATCH (eq:$(rec.EQUIPMENT_TYPE) {id:rec.EQUIPMENT_ID})\n",
    "      MERGE (a:Alert {id:rec.ID})\n",
    "      MERGE (eq)-[r:HAS_ALERT]->(a)\n",
    "      SET\n",
    "        a.type = rec.TYPE,\n",
    "        a.date = CASE\n",
    "            WHEN toString(rec.DATE) = 'NaN' OR rec.DATE IS NULL OR rec.DATE = ''\n",
    "            THEN NULL\n",
    "            ELSE date(rec.DATE)\n",
    "            END\n",
    "\n",
    "    return count(rec) AS records_upserted\n",
    "    \"\"\", routing_=RoutingControl.WRITE, result_transformer_=lambda r: r.data(), records=records)\n",
    "    print(res)"
   ],
   "id": "25a7fca8709852c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Unstructured Source",
   "id": "3aba6a0fb0b0e145"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "# Read from JSON file into array of Python objects\n",
    "with open(os.path.join(data_dir,'maintenance_records.json'), 'r') as file:\n",
    "    maintenance_record_texts = json.load(file)\n",
    "print(f\"Loaded {len(maintenance_record_texts)} records\")\n",
    "print(\"Sample:\")\n",
    "for rec in maintenance_record_texts[:3]:\n",
    "    print('-----')\n",
    "    print(rec)\n"
   ],
   "id": "95008ac66414a5f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from enum import Enum\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class MaintenanceType(str, Enum):\n",
    "    PREDICTIVE = \"Predictive\"\n",
    "    CORRECTIVE = \"Corrective\"\n",
    "    PREVENTIVE = \"Preventive\"\n",
    "    EMERGENCY = \"Emergency\"\n",
    "\n",
    "\n",
    "class MaintenanceRecord(BaseModel):\n",
    "    id: str = Field(..., description=\"The maintenance record id\")\n",
    "    equipmentId: int = Field(..., description=\"The equipment id\")\n",
    "    equipmentType: str = Field(..., description=\"The equipment type\")\n",
    "    description: str = Field(..., description=\"The maintenance record description in English.  \"\n",
    "                                              \"Translate as necessary. \"\n",
    "                                              \"Some description may be in different languages such \"\n",
    "                                              \"as Portuguese, Spanish, etc.\")\n",
    "    date: str = Field(..., description=\"the date of the maintenance record\")\n",
    "    downtimeInHours: int = Field(..., description=\"The downtime in hours.  These may not be labeled as hours, but numbers without units are hours by default.\")\n",
    "    type: MaintenanceType = Field(..., description=\"The maintenance record type\")\n",
    "    rootCause: str = Field(..., description=\"The root cause of the maintenance\")"
   ],
   "id": "526d656c8382b89e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import asyncio\n",
    "from typing import List\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pydantic import BaseModel\n",
    "from tqdm.asyncio import tqdm as tqdm_async\n",
    "\n",
    "\n",
    "class TextExtractor:\n",
    "    def __init__(self,\n",
    "                 llm_with_struct_output,\n",
    "                 prompt_template: PromptTemplate):\n",
    "        self.llm = llm_with_struct_output\n",
    "        self.prompt_template = prompt_template\n",
    "\n",
    "    async def extract(self, texts: List[str], semaphore) -> BaseModel:\n",
    "        async with semaphore:\n",
    "            prompt = self.prompt_template.invoke({'texts': '\\n\\n'.join(texts)})\n",
    "            # Use structured LLM for extraction\n",
    "            entity: BaseModel = await self.llm.ainvoke(prompt)\n",
    "        return entity\n",
    "\n",
    "\n",
    "    async def extract_all(self, texts: List[str], chunk_size=1, max_workers=10) -> List[BaseModel]:\n",
    "        # Create a semaphore with the desired number of workers\n",
    "        semaphore = asyncio.Semaphore(max_workers)\n",
    "\n",
    "        # Create tasks with the semaphore\n",
    "        text_chunks = chunks(texts, chunk_size)\n",
    "        tasks = [self.extract(text_chunk, semaphore) for text_chunk in text_chunks]\n",
    "\n",
    "        # Explicitly update progress using `tqdm` as tasks complete\n",
    "        entities: List[BaseModel] = []\n",
    "        with tqdm_async(total=len(tasks), desc=\"extracting texts\") as pbar:\n",
    "            for future in asyncio.as_completed(tasks):\n",
    "                result = await future\n",
    "                entities.append(result)\n",
    "                pbar.update(1)  # Increment progress bar for each completed task\n",
    "        return entities"
   ],
   "id": "1bac421855acd7fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "#Get LLM api key\n",
    "load_dotenv('source-db.env', override=True)\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI AI API key: \")\n",
    "\n",
    "# Define Prompt and LLM with structured output\n",
    "prompt_template = PromptTemplate.from_template(\"\"\"\n",
    "Extract and structure the maintenance information from the following text:\n",
    "\n",
    "# Text\n",
    "{texts}\n",
    "\"\"\")\n",
    "llm = ChatOpenAI(model=\"gpt-4.1\", temperature=0).with_structured_output(MaintenanceRecord)\n",
    "\n",
    "# Perform entity extraction\n",
    "text_extractor = TextExtractor(llm, prompt_template)\n",
    "maintenance_records = await text_extractor.extract_all(maintenance_record_texts)"
   ],
   "id": "f83cd04f64d80c59",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for maintenance_record in maintenance_records[:3]:\n",
    "    pprint(maintenance_record.model_dump())"
   ],
   "id": "c3e4d7748c783065",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for record_objects in chunks(maintenance_records):\n",
    "    records = [i.model_dump() for i in record_objects]\n",
    "    res = generator_df = driver.execute_query(\"\"\"\n",
    "      UNWIND $records as rec\n",
    "      MATCH (eq:$(rec.equipmentType) {id:rec.equipmentId})\n",
    "      MERGE (m:MaintenanceRecord {id:rec.id})\n",
    "      MERGE (eq)-[r:HAS_MAINTENANCE_RECORD]->(m)\n",
    "      SET\n",
    "        m.description = rec.description,\n",
    "        m.type = rec.type,\n",
    "        m.date = date(rec.date),\n",
    "        m.downtimeInHours = rec.downtimeInHours,\n",
    "        m.rootCause = rec.rootCause\n",
    "    return count(rec) AS records_upserted\n",
    "    \"\"\",\n",
    "        #database_=DATABASE,\n",
    "        routing_=RoutingControl.WRITE,\n",
    "        result_transformer_= lambda r: r.data(),\n",
    "        records = records\n",
    "    )\n",
    "    print(res)"
   ],
   "id": "af454b1fab5b0ac1",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
