{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Create Energy Graph\n",
    "\n",
    "This notebook will create a graph representing an energy grid with customer installations.\n",
    "\n",
    "It is split into two sections\n",
    "\n",
    "1. __Structured Source__: Tabular data. Ingestion is done with Cypher query templates (ordinary ETL)\n",
    "2. __Unstructured Source__: Text data. In this case maintenance records. In estion involves an LLM powered entity extraction step prior to loading with a Cypher query templates"
   ],
   "id": "5e2a9a893f992e18"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Structured Source",
   "id": "98c93e65ea4f7394"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-26T04:45:59.557240Z",
     "start_time": "2025-06-26T04:45:58.093270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from neo4j import GraphDatabase\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from getpass import getpass\n",
    "\n",
    "\n",
    "# get credentials\n",
    "load_dotenv('target-db.env', override=True)\n",
    "\n",
    "uri = os.getenv('NEO4J_URI')\n",
    "username = os.getenv('NEO4J_USERNAME')\n",
    "password = os.getenv('NEO4J_PASSWORD')\n",
    "\n",
    "if not uri:\n",
    "  uri = getpass(\"Please enter your Neo4j URI: \")\n",
    "if not username:\n",
    "  username = getpass(\"Please enter your Neo4j username: \")\n",
    "if not password:\n",
    "  password = getpass(\"Please enter your Neo4j password: \")\n",
    "\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T04:46:04.059126Z",
     "start_time": "2025-06-26T04:45:59.564093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from neo4j import RoutingControl\n",
    "\n",
    "#create uniqueness constraint if not exists\n",
    "driver.execute_query(\n",
    "    'CREATE CONSTRAINT IF NOT EXISTS FOR (n:Generator) REQUIRE (n.id) IS NODE KEY',\n",
    "    #database_=DATABASE,\n",
    "    routing_=RoutingControl.WRITE\n",
    ")\n",
    "\n",
    "driver.execute_query(\n",
    "    'CREATE CONSTRAINT IF NOT EXISTS FOR (n:Bus) REQUIRE (n.id) IS NODE KEY',\n",
    "    #database_=DATABASE,\n",
    "    routing_=RoutingControl.WRITE\n",
    ")\n",
    "\n",
    "driver.execute_query(\n",
    "    'CREATE CONSTRAINT IF NOT EXISTS FOR (n:Transformer) REQUIRE (n.id) IS NODE KEY',\n",
    "    #database_=DATABASE,\n",
    "    routing_=RoutingControl.WRITE\n",
    ")\n",
    "\n",
    "driver.execute_query(\n",
    "    'CREATE CONSTRAINT IF NOT EXISTS FOR (n:Link) REQUIRE (n.id) IS NODE KEY',\n",
    "    #database_=DATABASE,\n",
    "    routing_=RoutingControl.WRITE\n",
    ")\n",
    "\n",
    "driver.execute_query(\n",
    "    'CREATE CONSTRAINT IF NOT EXISTS FOR (n:Station) REQUIRE (n.id) IS NODE KEY',\n",
    "    #database_=DATABASE,\n",
    "    routing_=RoutingControl.WRITE\n",
    ")\n",
    "\n",
    "\n",
    "driver.execute_query(\n",
    "    'CREATE CONSTRAINT IF NOT EXISTS FOR (n:Customer) REQUIRE (n.id) IS NODE KEY',\n",
    "    #database_=DATABASE,\n",
    "    routing_=RoutingControl.WRITE\n",
    ")\n",
    "\n",
    "driver.execute_query(\n",
    "    'CREATE CONSTRAINT IF NOT EXISTS FOR (n:Installation) REQUIRE (n.id) IS NODE KEY',\n",
    "    #database_=DATABASE,\n",
    "    routing_=RoutingControl.WRITE\n",
    ")\n",
    "\n",
    "driver.execute_query(\n",
    "    'CREATE CONSTRAINT IF NOT EXISTS FOR (n:Region) REQUIRE (n.id) IS NODE KEY',\n",
    "    #database_=DATABASE,\n",
    "    routing_=RoutingControl.WRITE\n",
    ")\n",
    "\n",
    "driver.execute_query(\n",
    "    'CREATE CONSTRAINT IF NOT EXISTS FOR (n:Consumption) REQUIRE (n.id) IS NODE KEY',\n",
    "    #database_=DATABASE,\n",
    "    routing_=RoutingControl.WRITE\n",
    ")\n",
    "\n",
    "driver.execute_query(\n",
    "    'CREATE CONSTRAINT IF NOT EXISTS FOR (n:Ticket) REQUIRE (n.ticketNumber) IS NODE KEY',\n",
    "    #database_=DATABASE,\n",
    "    routing_=RoutingControl.WRITE\n",
    ")\n",
    "\n",
    "driver.execute_query(\n",
    "    'CREATE CONSTRAINT IF NOT EXISTS FOR (n:MaintenanceRecord) REQUIRE (n.id) IS NODE KEY',\n",
    "    #database_=DATABASE,\n",
    "    routing_=RoutingControl.WRITE\n",
    ")\n",
    "\n",
    "driver.execute_query(\n",
    "    'CREATE CONSTRAINT IF NOT EXISTS FOR (n:Alert) REQUIRE (n.id) IS NODE KEY',\n",
    "    #database_=DATABASE,\n",
    "    routing_=RoutingControl.WRITE\n",
    ")"
   ],
   "id": "84d2b5656245a31c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EagerResult(records=[], summary=<neo4j._work.summary.ResultSummary object at 0x12d2c8b50>, keys=[])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T04:46:04.203635Z",
     "start_time": "2025-06-26T04:46:04.201462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_dir = \"source-data\"\n",
    "# helper function\n",
    "def chunks(xs, n=1_000):\n",
    "    n = max(1, n)\n",
    "    return [xs[i:i + n] for i in range(0, len(xs), n)]"
   ],
   "id": "7cacfdbe8c9f6713",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T04:46:05.964578Z",
     "start_time": "2025-06-26T04:46:04.214722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from neo4j import RoutingControl\n",
    "\n",
    "generator_df = pd.read_csv(os.path.join(data_dir,'generators.csv'))\n",
    "\n",
    "for records in chunks(generator_df.to_dict(orient='records')):\n",
    "    res = generator_df = driver.execute_query(\"\"\"\n",
    "      UNWIND $records as rec\n",
    "      MERGE (g:Generator {id:rec.ID})\n",
    "      MERGE (b:Bus {id:rec.BUS_ID})\n",
    "      MERGE (g)-[r:CONNECTED]->(b)\n",
    "      SET\n",
    "        g.capacity = rec.CAPACITY,\n",
    "        g.category = rec.CATEGORY,\n",
    "        g.geometry = point({latitude: rec.LATITUDE, longitude: rec.LONGITUDE}),\n",
    "        g.mb_symbol = rec.MB_SYMBOL,\n",
    "        g.name_eng = rec.NAME_ENG,\n",
    "        g.name_nat = rec.NAME_NAT,\n",
    "        g.symbol = rec.SYMBOL,\n",
    "        g.tso = rec.TSO,\n",
    "        g.visible = rec.VISIBLE\n",
    "      RETURN count(rec) AS records_upserted\n",
    "    \"\"\",\n",
    "        #database_=DATABASE,\n",
    "        routing_=RoutingControl.WRITE,\n",
    "        result_transformer_= lambda r: r.data(),\n",
    "        records = records\n",
    "    )\n",
    "    print(res)"
   ],
   "id": "9cc6b0ab8273207c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'records_upserted': 1000}]\n",
      "[{'records_upserted': 1000}]\n",
      "[{'records_upserted': 172}]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T04:46:08.850933Z",
     "start_time": "2025-06-26T04:46:05.972652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bus_df = pd.read_csv(os.path.join(data_dir,'buses.csv'))\n",
    "\n",
    "for records in chunks(bus_df.to_dict(orient='records')):\n",
    "    res = driver.execute_query(\"\"\"\n",
    "      UNWIND $records AS rec\n",
    "      MERGE (b:Bus {id: rec.ID})\n",
    "      MERGE (s:Station {id: rec.STATION_ID})\n",
    "      MERGE (b)-[:IN_STATION]->(s)\n",
    "      SET\n",
    "        b.category = rec.CATEGORY,\n",
    "        b.geometry = point({latitude: rec.LATITUDE, longitude: rec.LONGITUDE}),\n",
    "        b.mb_symbol = rec.MB_SYMBOL,\n",
    "        b.name_eng = rec.NAME_ENG,\n",
    "        b.name_nat = rec.NAME_NAT,\n",
    "        b.symbol = rec.SYMBOL,\n",
    "        b.tso = rec.TSO,\n",
    "        b.visible = rec.VISIBLE,\n",
    "        b.voltage = rec.VOLTAGE\n",
    "      RETURN count(rec) AS records_upserted\n",
    "    \"\"\", routing_=RoutingControl.WRITE, result_transformer_=lambda r: r.data(), records=records)\n",
    "    print(res)"
   ],
   "id": "4ba47c64be68490a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'records_upserted': 1000}]\n",
      "[{'records_upserted': 1000}]\n",
      "[{'records_upserted': 1000}]\n",
      "[{'records_upserted': 1000}]\n",
      "[{'records_upserted': 1000}]\n",
      "[{'records_upserted': 1000}]\n",
      "[{'records_upserted': 1000}]\n",
      "[{'records_upserted': 893}]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T04:46:09.554385Z",
     "start_time": "2025-06-26T04:46:08.858922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transformer_df = pd.read_csv(os.path.join(data_dir,'transformers.csv'))\n",
    "\n",
    "for records in chunks(transformer_df.to_dict(orient='records')):\n",
    "    res = driver.execute_query(\"\"\"\n",
    "      UNWIND $records AS rec\n",
    "      MERGE (t:Transformer {id: rec.ID})\n",
    "      MERGE (b:Bus {id: rec.BUS_ID})\n",
    "      MERGE (t)-[:CONNECTED]->(b)\n",
    "      SET\n",
    "        t.dst_dc = rec.DST_DC,\n",
    "        t.dst_voltage = rec.DST_VOLTAGE,\n",
    "        t.geometry = point({latitude: rec.LATITUDE, longitude: rec.LONGITUDE}),\n",
    "        t.src_dc = rec.SRC_DC,\n",
    "        t.src_voltage = rec.SRC_VOLTAGE,\n",
    "        t.symbol = rec.SYMBOL\n",
    "      RETURN count(rec) AS records_upserted\n",
    "    \"\"\", routing_=RoutingControl.WRITE, result_transformer_=lambda r: r.data(), records=records)\n",
    "    print(res)"
   ],
   "id": "c345c529a8ed45b9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'records_upserted': 1000}]\n",
      "[{'records_upserted': 60}]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T04:46:12.864694Z",
     "start_time": "2025-06-26T04:46:09.567369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "link_df = pd.read_csv(os.path.join(data_dir,'links.csv'))\n",
    "\n",
    "for records in chunks(link_df.to_dict(orient='records')):\n",
    "    res = driver.execute_query(\"\"\"\n",
    "      UNWIND $records AS rec\n",
    "      MERGE (l:Link {id: rec.ID})\n",
    "      MERGE (b:Bus {id: rec.BUS_ID})\n",
    "      MERGE (l)-[:CONNECTED]->(b)\n",
    "      SET\n",
    "        l.circuits = rec.CIRCUITS,\n",
    "        l.dc = rec.DC,\n",
    "        l.length_m = rec.LENGTH_M,\n",
    "        l.shape_leng = rec.SHAPE_LENG,\n",
    "        l.symbol = rec.SYMBOL,\n",
    "        l.t9_code = rec.T9_CODE,\n",
    "        l.underground = rec.UNDERGROUND,\n",
    "        l.visible = rec.VISIBLE,\n",
    "        l.voltage = rec.VOLTAGE\n",
    "      RETURN count(rec) AS records_upserted\n",
    "    \"\"\", routing_=RoutingControl.WRITE, result_transformer_=lambda r: r.data(), records=records)\n",
    "    print(res)"
   ],
   "id": "fa27ea49d69401e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'records_upserted': 1000}]\n",
      "[{'records_upserted': 1000}]\n",
      "[{'records_upserted': 1000}]\n",
      "[{'records_upserted': 1000}]\n",
      "[{'records_upserted': 1000}]\n",
      "[{'records_upserted': 1000}]\n",
      "[{'records_upserted': 1000}]\n",
      "[{'records_upserted': 1000}]\n",
      "[{'records_upserted': 1000}]\n",
      "[{'records_upserted': 784}]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T04:46:14.726192Z",
     "start_time": "2025-06-26T04:46:12.882257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "station_df = pd.read_csv(os.path.join(data_dir,'stations.csv'))\n",
    "\n",
    "for records in chunks(station_df.to_dict(orient='records')):\n",
    "    res = driver.execute_query(\"\"\"\n",
    "      UNWIND $records AS rec\n",
    "      MERGE (s:Station {id: rec.ID})\n",
    "      SET\n",
    "        s.name_eng = rec.NAME_ENG,\n",
    "        s.geometry = point({latitude: rec.LATITUDE, longitude: rec.LONGITUDE})\n",
    "      RETURN count(rec) AS records_upserted\n",
    "    \"\"\", routing_=RoutingControl.WRITE, result_transformer_=lambda r: r.data(), records=records)\n",
    "    print(res)\n"
   ],
   "id": "735e927e2b72dcbb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'records_upserted': 1000}]\n",
      "[{'records_upserted': 1000}]\n",
      "[{'records_upserted': 1000}]\n",
      "[{'records_upserted': 1000}]\n",
      "[{'records_upserted': 1000}]\n",
      "[{'records_upserted': 1000}]\n",
      "[{'records_upserted': 811}]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T04:46:15.009285Z",
     "start_time": "2025-06-26T04:46:14.737271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "customer_df = pd.read_csv(os.path.join(data_dir,'customers.csv'))\n",
    "\n",
    "for records in chunks(customer_df.to_dict(orient='records')):\n",
    "    res = driver.execute_query(\"\"\"\n",
    "      UNWIND $records AS rec\n",
    "      MERGE (c:Customer {id: rec.ID})\n",
    "      SET\n",
    "        c.name = rec.NAME,\n",
    "        c.type = rec.TYPE\n",
    "      RETURN count(rec) AS records_upserted\n",
    "    \"\"\", routing_=RoutingControl.WRITE, result_transformer_=lambda r: r.data(), records=records)\n",
    "    print(res)\n"
   ],
   "id": "e8b67b23c8f788eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'records_upserted': 230}]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T04:46:16.124374Z",
     "start_time": "2025-06-26T04:46:15.018539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "installation_df = pd.read_csv(os.path.join(data_dir,'installations.csv'))\n",
    "\n",
    "for records in chunks(installation_df.to_dict(orient='records')):\n",
    "    res = driver.execute_query(\"\"\"\n",
    "      UNWIND $records AS rec\n",
    "      MERGE (i:Installation {id: rec.ID})\n",
    "      SET\n",
    "        i.installationDate = rec.INSTALLATIONDATE,\n",
    "        i.nome = rec.NOME,\n",
    "        i.type = rec.TYPE\n",
    "      RETURN count(rec) AS records_upserted\n",
    "    \"\"\", routing_=RoutingControl.WRITE, result_transformer_=lambda r: r.data(), records=records)\n",
    "    print(res)\n",
    "\n",
    "# Due to data quality issues a minority of installations are missing customers, links, and/or region. We work around for now\n",
    "for records in chunks(installation_df[~installation_df.LINK_ID.isna()].to_dict(orient='records')):\n",
    "    res = driver.execute_query(\"\"\"\n",
    "      UNWIND $records AS rec\n",
    "      MERGE (i:Installation {id: rec.ID})\n",
    "      MERGE (l:Link {id: rec.LINK_ID})\n",
    "      MERGE (l)-[:LINK_HAS_INSTALLATION]->(i)\n",
    "      RETURN count(rec) AS records_upserted\n",
    "    \"\"\", routing_=RoutingControl.WRITE, result_transformer_=lambda r: r.data(), records=records)\n",
    "    print(res)\n",
    "\n",
    "for records in chunks(installation_df[~installation_df.CUSTOMER_ID.isna()].to_dict(orient='records')):\n",
    "    res = driver.execute_query(\"\"\"\n",
    "      UNWIND $records AS rec\n",
    "      MERGE (i:Installation {id: rec.ID})\n",
    "      MERGE (c:Customer {id: rec.CUSTOMER_ID})\n",
    "      MERGE (c)-[:CUSTOMER_HAS_INSTALLATION]->(i)\n",
    "      RETURN count(rec) AS records_upserted\n",
    "    \"\"\", routing_=RoutingControl.WRITE, result_transformer_=lambda r: r.data(), records=records)\n",
    "    print(res)\n",
    "\n",
    "for records in chunks(installation_df[~installation_df.REGION_ID.isna()].to_dict(orient='records')):\n",
    "    res = driver.execute_query(\"\"\"\n",
    "      UNWIND $records AS rec\n",
    "      MERGE (i:Installation {id: rec.ID})\n",
    "      MERGE (r:Region {id: rec.REGION_ID})\n",
    "      MERGE (i)-[:INSTALL_HAS_REGION]->(r)\n",
    "      RETURN count(rec) AS records_upserted\n",
    "    \"\"\", routing_=RoutingControl.WRITE, result_transformer_=lambda r: r.data(), records=records)\n",
    "    print(res)\n"
   ],
   "id": "7f0718e80ae1fbdb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'records_upserted': 30}]\n",
      "[{'records_upserted': 26}]\n",
      "[{'records_upserted': 23}]\n",
      "[{'records_upserted': 30}]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T04:46:16.399663Z",
     "start_time": "2025-06-26T04:46:16.142399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "region_df = pd.read_csv(os.path.join(data_dir,'regions.csv'))\n",
    "\n",
    "for records in chunks(region_df.to_dict(orient='records')):\n",
    "    res = driver.execute_query(\"\"\"\n",
    "      UNWIND $records AS rec\n",
    "      MERGE (r:Region {id: rec.ID})\n",
    "      SET r.name = rec.NAME\n",
    "      RETURN count(rec) AS records_upserted\n",
    "    \"\"\", routing_=RoutingControl.WRITE, result_transformer_=lambda r: r.data(), records=records)\n",
    "    print(res)"
   ],
   "id": "1d13624cd77e00de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'records_upserted': 4}]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T04:46:17.305571Z",
     "start_time": "2025-06-26T04:46:16.413023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "consumption_df = pd.read_csv(os.path.join(data_dir,'consumption_logs.csv'))\n",
    "\n",
    "for records in chunks(consumption_df.to_dict(orient='records')):\n",
    "    res = driver.execute_query(\"\"\"\n",
    "      UNWIND $records AS rec\n",
    "      MERGE (c:Consumption {id: rec.ID})\n",
    "      MERGE (i:Installation {id: rec.INSTALLATION_ID})\n",
    "      MERGE (i)-[:INSTALL_HAS_CONSUMPTION]->(c)\n",
    "      SET\n",
    "        c.seqId = rec.SEQ_ID,\n",
    "        c.referenceDate = rec.REFERENCEDATE,\n",
    "        c.quantity = rec.QUANTIDADE,\n",
    "        c.consumptionValue = rec.CONSUMPTIONVALUE,\n",
    "        c.invoiceValue = rec.INVOICEVALUE,\n",
    "        c.newConsumptionValue = rec.NEWCONSUMPTIONVALUE\n",
    "      //add NEXT relationships\n",
    "      WITH c,i, rec\n",
    "      MATCH (i)-[:INSTALL_HAS_CONSUMPTION]->(c_next:Consumption {seqId: c.seqId + 1})\n",
    "      MERGE (c)-[:NEXT]->(c_next)\n",
    "      RETURN count(rec) AS records_upserted\n",
    "    \"\"\", routing_=RoutingControl.WRITE, result_transformer_=lambda r: r.data(), records=records)\n",
    "    print(res)\n",
    "\n",
    "# First\n",
    "res = driver.execute_query(\"\"\"\n",
    "MATCH(i:Installation)-[:INSTALL_HAS_CONSUMPTION]->(c)\n",
    "WHERE COUNT{()-[:NEXT]->(c)} = 0\n",
    "MERGE (i)-[r:FIRST]->(c)\n",
    "RETURN count(r) AS relationships_written\n",
    "\"\"\", routing_=RoutingControl.WRITE, result_transformer_=lambda r: r.data())\n",
    "print(res)\n",
    "\n",
    "# Last\n",
    "res = driver.execute_query(\"\"\"\n",
    "MATCH(i:Installation)-[:INSTALL_HAS_CONSUMPTION]->(c)\n",
    "WHERE COUNT{(c)-[:NEXT]->()} = 0\n",
    "MERGE (i)-[r:LAST]->(c)\n",
    "RETURN count(r) AS relationships_written\n",
    "\"\"\", routing_=RoutingControl.WRITE, result_transformer_=lambda r: r.data())\n",
    "print(res)"
   ],
   "id": "a116e4ce36cd2eb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'records_upserted': 330}]\n",
      "[{'relationships_written': 30}]\n",
      "[{'relationships_written': 30}]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T04:46:17.621831Z",
     "start_time": "2025-06-26T04:46:17.308449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ticket_df = pd.read_csv(os.path.join(data_dir,'tickets.csv'))\n",
    "\n",
    "for records in chunks(ticket_df.to_dict(orient='records')):\n",
    "    res = driver.execute_query(\"\"\"\n",
    "      UNWIND $records AS rec\n",
    "      MERGE (t:Ticket {ticketNumber: rec.TICKETNUMBER})\n",
    "      MERGE (c:Customer {id: rec.CUSTOMER_ID})\n",
    "      MERGE (c)-[:CREATED_TICKET]->(t)\n",
    "      SET\n",
    "        t.createdDate = rec.CREATEDATE,\n",
    "        t.resolutionDate = rec.RESOLUTIONDATE,\n",
    "        t.severity = rec.SEVERITY,\n",
    "        t.status = rec.STATUS\n",
    "      RETURN count(rec) AS records_upserted\n",
    "    \"\"\", routing_=RoutingControl.WRITE, result_transformer_=lambda r: r.data(), records=records)\n",
    "    print(res)"
   ],
   "id": "4a535106f17011a9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'records_upserted': 194}]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T04:46:18.025495Z",
     "start_time": "2025-06-26T04:46:17.633621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "alert_df = pd.read_csv(os.path.join(data_dir,'alerts.csv'))\n",
    "\n",
    "for records in chunks(alert_df.to_dict(orient='records')):\n",
    "    res = driver.execute_query(\"\"\"\n",
    "      UNWIND $records AS rec\n",
    "      MATCH (eq:$(rec.EQUIPMENT_TYPE) {id:rec.EQUIPMENT_ID})\n",
    "      MERGE (a:Alert {id:rec.ID})\n",
    "      MERGE (eq)-[r:HAS_ALERT]->(a)\n",
    "      SET\n",
    "        a.type = rec.TYPE,\n",
    "        a.date = CASE\n",
    "            WHEN toString(rec.DATE) = 'NaN' OR rec.DATE IS NULL OR rec.DATE = ''\n",
    "            THEN NULL\n",
    "            ELSE date(rec.DATE)\n",
    "            END\n",
    "\n",
    "    return count(rec) AS records_upserted\n",
    "    \"\"\", routing_=RoutingControl.WRITE, result_transformer_=lambda r: r.data(), records=records)\n",
    "    print(res)"
   ],
   "id": "25a7fca8709852c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'records_upserted': 8}]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Unstructured Source",
   "id": "3aba6a0fb0b0e145"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T04:46:18.041250Z",
     "start_time": "2025-06-26T04:46:18.038033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "# Read from JSON file into array of Python objects\n",
    "with open(os.path.join(data_dir,'maintenance_records.json'), 'r') as file:\n",
    "    maintenance_record_texts = json.load(file)\n",
    "print(f\"Loaded {len(maintenance_record_texts)} records\")\n",
    "print(\"Sample:\")\n",
    "for rec in maintenance_record_texts[:3]:\n",
    "    print('-----')\n",
    "    print(rec)\n"
   ],
   "id": "95008ac66414a5f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 30 records\n",
      "Sample:\n",
      "-----\n",
      "Maintenance Record ID: MR123491\n",
      "Equipment ID: 1498\n",
      "Equipment Type: Bus\n",
      "Date: 2024-06-19\n",
      "\n",
      "Type of Maintenance: Preventive\n",
      "Root Cause: Isolamento (Insulation)\n",
      "\n",
      "Description:\n",
      "Performed a preventive maintenance check focused on the insulation of the busbar. The main objective was to verify that there is no degradation in the insulation that could potentially lead to electrical failures. Insulation resistance tests were carried out and all results were within acceptable parameters. No significant issues or abnormalities were detected during the inspection. The technician confirmed that the insulation is in excellent condition at this time. It is recommended to continue with the annual insulation checks as part of the regular maintenance schedule.\n",
      "\n",
      "Total Downtime: 2 hours\n",
      "\n",
      "Technician's Note: All insulation tests passed. No corrective actions required at this time.\n",
      "-----\n",
      "Maintenance Record ID: MR123492\n",
      "Equipment ID: 6808\n",
      "Equipment Type: Bus\n",
      "Date: 2024-06-20\n",
      "\n",
      "Description:\n",
      "A complete replacement of a damaged bus was performed due to structural failure (root cause: Falha Estrutural). The corrective maintenance involved removing the old, structurally compromised bus, which was then dismantled and all debris was disposed of in accordance with safety and environmental guidelines. A new bus was installed and thoroughly tested to ensure proper operation. The technician noted that the new installation has significantly improved the reliability of the system. It was recommended that regular inspections be scheduled to prevent similar issues in the future. Total downtime for this intervention was 6 hours.\n",
      "-----\n",
      "Maintenance Record ID: MR123484\n",
      "Equipment ID: 2822\n",
      "Equipment Type: Link\n",
      "\n",
      "Date: 2024-06-12\n",
      "Type: Preventive\n",
      "\n",
      "Description:\n",
      "On June 12, 2024, a preventive maintenance check was performed on Link equipment (ID: 2822). The main focus was on assessing meteorological conditions, specifically wind, temperature, and humidity, as these factors can significantly impact the stability of the transmission line. Preventive adjustments were carried out to mitigate any potential risks and ensure continued stable operation. The root cause for this intervention was identified as 'Condições Meteorológicas' (Weather Conditions). The total downtime for this maintenance activity was 1 hour.\n",
      "\n",
      "All adjustments were completed successfully, and the equipment was returned to normal operation.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T04:46:18.157330Z",
     "start_time": "2025-06-26T04:46:18.055121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from enum import Enum\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class MaintenanceType(str, Enum):\n",
    "    PREDICTIVE = \"Predictive\"\n",
    "    CORRECTIVE = \"Corrective\"\n",
    "    PREVENTIVE = \"Preventive\"\n",
    "    EMERGENCY = \"Emergency\"\n",
    "\n",
    "\n",
    "class MaintenanceRecord(BaseModel):\n",
    "    id: str = Field(..., description=\"The maintenance record id\")\n",
    "    equipmentId: int = Field(..., description=\"The equipment id\")\n",
    "    equipmentType: str = Field(..., description=\"The equipment type\")\n",
    "    description: str = Field(..., description=\"The maintenance record description in English.  \"\n",
    "                                              \"Translate as necessary. \"\n",
    "                                              \"Some description may be in different languages such \"\n",
    "                                              \"as Portuguese, Spanish, etc.\")\n",
    "    date: str = Field(..., description=\"the date of the maintenance record\")\n",
    "    downtimeInHours: int = Field(..., description=\"The downtime in hours.  These may not be labeled as hours, but numbers without units are hours by default.\")\n",
    "    type: MaintenanceType = Field(..., description=\"The maintenance record type\")\n",
    "    rootCause: str = Field(..., description=\"The root cause of the maintenance\")"
   ],
   "id": "526d656c8382b89e",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T04:46:18.341271Z",
     "start_time": "2025-06-26T04:46:18.177750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import asyncio\n",
    "from typing import List\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pydantic import BaseModel\n",
    "from tqdm.asyncio import tqdm as tqdm_async\n",
    "\n",
    "\n",
    "class TextExtractor:\n",
    "    def __init__(self,\n",
    "                 llm_with_struct_output,\n",
    "                 prompt_template: PromptTemplate):\n",
    "        self.llm = llm_with_struct_output\n",
    "        self.prompt_template = prompt_template\n",
    "\n",
    "    async def extract(self, texts: List[str], semaphore) -> BaseModel:\n",
    "        async with semaphore:\n",
    "            prompt = self.prompt_template.invoke({'texts': '\\n\\n'.join(texts)})\n",
    "            # Use structured LLM for extraction\n",
    "            entity: BaseModel = await self.llm.ainvoke(prompt)\n",
    "        return entity\n",
    "\n",
    "\n",
    "    async def extract_all(self, texts: List[str], chunk_size=1, max_workers=10) -> List[BaseModel]:\n",
    "        # Create a semaphore with the desired number of workers\n",
    "        semaphore = asyncio.Semaphore(max_workers)\n",
    "\n",
    "        # Create tasks with the semaphore\n",
    "        text_chunks = chunks(texts, chunk_size)\n",
    "        tasks = [self.extract(text_chunk, semaphore) for text_chunk in text_chunks]\n",
    "\n",
    "        # Explicitly update progress using `tqdm` as tasks complete\n",
    "        entities: List[BaseModel] = []\n",
    "        with tqdm_async(total=len(tasks), desc=\"extracting texts\") as pbar:\n",
    "            for future in asyncio.as_completed(tasks):\n",
    "                result = await future\n",
    "                entities.append(result)\n",
    "                pbar.update(1)  # Increment progress bar for each completed task\n",
    "        return entities"
   ],
   "id": "1bac421855acd7fe",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T04:46:30.717048Z",
     "start_time": "2025-06-26T04:46:18.354933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "#Get LLM api key\n",
    "load_dotenv('source-db.env', override=True)\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI AI API key: \")\n",
    "\n",
    "# Define Prompt and LLM with structured output\n",
    "prompt_template = PromptTemplate.from_template(\"\"\"\n",
    "Extract and structure the maintenance information from the following text:\n",
    "\n",
    "# Text\n",
    "{texts}\n",
    "\"\"\")\n",
    "llm = ChatOpenAI(model=\"gpt-4.1\", temperature=0).with_structured_output(MaintenanceRecord)\n",
    "\n",
    "# Perform entity extraction\n",
    "text_extractor = TextExtractor(llm, prompt_template)\n",
    "maintenance_records = await text_extractor.extract_all(maintenance_record_texts)"
   ],
   "id": "f83cd04f64d80c59",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extracting texts: 100%|██████████| 30/30 [00:11<00:00,  2.56it/s]\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T04:46:30.726978Z",
     "start_time": "2025-06-26T04:46:30.724037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for maintenance_record in maintenance_records[:3]:\n",
    "    pprint(maintenance_record.model_dump())"
   ],
   "id": "c3e4d7748c783065",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'date': '2024-06-03',\n",
      " 'description': 'During a scheduled preventive maintenance inspection, '\n",
      "                'corrosion was found on the electrical cable connections. The '\n",
      "                'affected connections were thoroughly cleaned and treated with '\n",
      "                'an anti-corrosive compound to prevent further deterioration. '\n",
      "                'The root cause of the issue was identified as corrosion.',\n",
      " 'downtimeInHours': 1,\n",
      " 'equipmentId': 1498,\n",
      " 'equipmentType': 'Bus',\n",
      " 'id': 'MR123475',\n",
      " 'rootCause': 'Corrosion on electrical cable connections.',\n",
      " 'type': <MaintenanceType.PREVENTIVE: 'Preventive'>}\n",
      "{'date': '2024-06-07',\n",
      " 'description': 'During a routine predictive maintenance check using '\n",
      "                'thermographic (infrared) cameras, several hot spots were '\n",
      "                'detected on the bus. These hot spots are indicative of '\n",
      "                'potential contact failures, which could lead to more serious '\n",
      "                'issues if left unaddressed. Based on the findings, preventive '\n",
      "                'maintenance was immediately performed on all identified '\n",
      "                'points to mitigate any risk of failure. The root cause was '\n",
      "                'determined to be related to contact issues as revealed by the '\n",
      "                'thermography inspection. Total downtime for this intervention '\n",
      "                'was 1 hour.',\n",
      " 'downtimeInHours': 1,\n",
      " 'equipmentId': 1536,\n",
      " 'equipmentType': 'Bus',\n",
      " 'id': 'MR123479',\n",
      " 'rootCause': 'Thermography (contact issues revealed by infrared inspection)',\n",
      " 'type': <MaintenanceType.PREDICTIVE: 'Predictive'>}\n",
      "{'date': '2024-06-11',\n",
      " 'description': 'Voltage and current measurements were performed on the '\n",
      "                \"equipment to ensure all values were within the manufacturer's \"\n",
      "                'specified limits. During the inspection, small deviations '\n",
      "                'were identified and corrected by adjusting electrical '\n",
      "                'parameters. After the adjustments, values returned to the '\n",
      "                'expected standard. The procedure was completed without '\n",
      "                'incidents and the equipment was released for operation.',\n",
      " 'downtimeInHours': 2,\n",
      " 'equipmentId': 10437,\n",
      " 'equipmentType': 'Link',\n",
      " 'id': 'MR123483',\n",
      " 'rootCause': 'Electrical verification',\n",
      " 'type': <MaintenanceType.PREVENTIVE: 'Preventive'>}\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T04:46:31.831986Z",
     "start_time": "2025-06-26T04:46:30.753261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for record_objects in chunks(maintenance_records):\n",
    "    records = [i.model_dump() for i in record_objects]\n",
    "    res = generator_df = driver.execute_query(\"\"\"\n",
    "      UNWIND $records as rec\n",
    "      MATCH (eq:$(rec.equipmentType) {id:rec.equipmentId})\n",
    "      MERGE (m:MaintenanceRecord {id:rec.id})\n",
    "      MERGE (eq)-[r:HAS_MAINTENANCE_RECORD]->(m)\n",
    "      SET\n",
    "        m.description = rec.description,\n",
    "        m.type = rec.type,\n",
    "        m.date = date(rec.date),\n",
    "        m.downtimeInHours = rec.downtimeInHours,\n",
    "        m.rootCause = rec.rootCause\n",
    "    return count(rec) AS records_upserted\n",
    "    \"\"\",\n",
    "        #database_=DATABASE,\n",
    "        routing_=RoutingControl.WRITE,\n",
    "        result_transformer_= lambda r: r.data(),\n",
    "        records = records\n",
    "    )\n",
    "    print(res)"
   ],
   "id": "af454b1fab5b0ac1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'records_upserted': 30}]\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Embeddings",
   "id": "2705cf91e586dc50"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T04:46:34.765205Z",
     "start_time": "2025-06-26T04:46:31.837461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model='text-embedding-ada-002')\n",
    "maintenance_record_emb_df = pd.DataFrame({\n",
    "    'id': [r.id for r in maintenance_records],\n",
    "    'text': [r.model_dump_json(indent=2) for r in maintenance_records]\n",
    "})\n",
    "\n",
    "embeddings = []\n",
    "# Use tqdm to show progress during embedding generation\n",
    "for chunk in tqdm(chunks(maintenance_record_emb_df['text'], n=10), desc=\"Processing embedding chunks\"):\n",
    "    # Generate embeddings for each chunk and extend the embeddings list\n",
    "    embeddings.extend(embedding_model.embed_documents(chunk))\n",
    "maintenance_record_emb_df['embedding'] = embeddings\n",
    "maintenance_record_emb_df"
   ],
   "id": "3a1533773d2ce7ba",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing embedding chunks: 100%|██████████| 3/3 [00:02<00:00,  1.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "          id                                               text  \\\n",
       "0   MR123475  {\\n  \"id\": \"MR123475\",\\n  \"equipmentId\": 1498,...   \n",
       "1   MR123479  {\\n  \"id\": \"MR123479\",\\n  \"equipmentId\": 1536,...   \n",
       "2   MR123483  {\\n  \"id\": \"MR123483\",\\n  \"equipmentId\": 10437...   \n",
       "3   MR123459  {\\n  \"id\": \"MR123459\",\\n  \"equipmentId\": 1540,...   \n",
       "4   MR123472  {\\n  \"id\": \"MR123472\",\\n  \"equipmentId\": 534,\\...   \n",
       "5   MR123486  {\\n  \"id\": \"MR123486\",\\n  \"equipmentId\": 917,\\...   \n",
       "6   MR123458  {\\n  \"id\": \"MR123458\",\\n  \"equipmentId\": 514,\\...   \n",
       "7   MR123493  {\\n  \"id\": \"MR123493\",\\n  \"equipmentId\": 1538,...   \n",
       "8   MR123470  {\\n  \"id\": \"MR123470\",\\n  \"equipmentId\": 528,\\...   \n",
       "9   MR123466  {\\n  \"id\": \"MR123466\",\\n  \"equipmentId\": 534,\\...   \n",
       "10  MR123496  {\\n  \"id\": \"MR123496\",\\n  \"equipmentId\": 917,\\...   \n",
       "11  MR123457  {\\n  \"id\": \"MR123457\",\\n  \"equipmentId\": 536,\\...   \n",
       "12  MR123456  {\\n  \"id\": \"MR123456\",\\n  \"equipmentId\": 528,\\...   \n",
       "13  MR123481  {\\n  \"id\": \"MR123481\",\\n  \"equipmentId\": 3348,...   \n",
       "14  MR123492  {\\n  \"id\": \"MR123492\",\\n  \"equipmentId\": 6808,...   \n",
       "15  MR123487  {\\n  \"id\": \"MR123487\",\\n  \"equipmentId\": 917,\\...   \n",
       "16  MR123489  {\\n  \"id\": \"MR123489\",\\n  \"equipmentId\": 1563,...   \n",
       "17  MR123491  {\\n  \"id\": \"MR123491\",\\n  \"equipmentId\": 1498,...   \n",
       "18  MR123497  {\\n  \"id\": \"MR123497\",\\n  \"equipmentId\": 1563,...   \n",
       "19  MR123467  {\\n  \"id\": \"MR123467\",\\n  \"equipmentId\": 536,\\...   \n",
       "20  MR123461  {\\n  \"id\": \"MR123461\",\\n  \"equipmentId\": 2665,...   \n",
       "21  MR123460  {\\n  \"id\": \"MR123460\",\\n  \"equipmentId\": 585,\\...   \n",
       "22  MR123476  {\\n  \"id\": \"MR123476\",\\n  \"equipmentId\": 917,\\...   \n",
       "23  MR123471  {\\n  \"id\": \"MR123471\",\\n  \"equipmentId\": 534,\\...   \n",
       "24  MR123484  {\\n  \"id\": \"MR123484\",\\n  \"equipmentId\": 2822,...   \n",
       "25  MR123499  {\\n  \"id\": \"MR123499\",\\n  \"equipmentId\": 1134,...   \n",
       "26  MR123477  {\\n  \"id\": \"MR123477\",\\n  \"equipmentId\": 2822,...   \n",
       "27  MR123478  {\\n  \"id\": \"MR123478\",\\n  \"equipmentId\": 2666,...   \n",
       "28  MR123488  {\\n  \"id\": \"MR123488\",\\n  \"equipmentId\": 1500,...   \n",
       "29  MR123468  {\\n  \"id\": \"MR123468\",\\n  \"equipmentId\": 585,\\...   \n",
       "\n",
       "                                            embedding  \n",
       "0   [-0.01116291806101799, 0.019062932580709457, 0...  \n",
       "1   [-0.016143329441547394, 0.017019763588905334, ...  \n",
       "2   [-0.013982994481921196, 0.022177550941705704, ...  \n",
       "3   [-0.028072549030184746, 0.02523903176188469, -...  \n",
       "4   [-0.018862921744585037, 0.008050049655139446, ...  \n",
       "5   [-0.018444092944264412, 0.020266413688659668, ...  \n",
       "6   [-0.00962898600846529, 0.011362914927303791, -...  \n",
       "7   [-0.015068135224282742, 0.013776778243482113, ...  \n",
       "8   [-0.014766044914722443, 0.015853628516197205, ...  \n",
       "9   [-0.020434923470020294, 0.008312629535794258, ...  \n",
       "10  [-0.008990037254989147, 0.017453286796808243, ...  \n",
       "11  [-0.0118974968791008, 0.020322881639003754, -0...  \n",
       "12  [-0.018081363290548325, 0.010219598188996315, ...  \n",
       "13  [-0.019523009657859802, 0.007061217445880175, ...  \n",
       "14  [-0.02487773448228836, 0.03101968951523304, -0...  \n",
       "15  [-0.003283120458945632, 0.025818848982453346, ...  \n",
       "16  [-0.020969154313206673, 0.027844060212373734, ...  \n",
       "17  [-0.01616201177239418, 0.025758204981684685, -...  \n",
       "18  [-0.018444161862134933, 0.031084412708878517, ...  \n",
       "19  [-0.018159152939915657, 0.014184696599841118, ...  \n",
       "20  [-0.022699303925037384, 0.01569691300392151, -...  \n",
       "21  [-0.022052135318517685, 0.004048418253660202, ...  \n",
       "22  [-0.017977172508835793, 0.012858176603913307, ...  \n",
       "23  [-0.035162024199962616, 0.006526491139084101, ...  \n",
       "24  [-0.014447738416492939, 0.01580478437244892, -...  \n",
       "25  [-0.022939378395676613, 0.029363524168729782, ...  \n",
       "26  [-0.007647366262972355, 0.01640325039625168, 0...  \n",
       "27  [-0.013953953981399536, 0.005004465114325285, ...  \n",
       "28  [-0.020427199080586433, 0.018171433359384537, ...  \n",
       "29  [-0.02139914594590664, 0.0035335849970579147, ...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MR123475</td>\n",
       "      <td>{\\n  \"id\": \"MR123475\",\\n  \"equipmentId\": 1498,...</td>\n",
       "      <td>[-0.01116291806101799, 0.019062932580709457, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MR123479</td>\n",
       "      <td>{\\n  \"id\": \"MR123479\",\\n  \"equipmentId\": 1536,...</td>\n",
       "      <td>[-0.016143329441547394, 0.017019763588905334, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MR123483</td>\n",
       "      <td>{\\n  \"id\": \"MR123483\",\\n  \"equipmentId\": 10437...</td>\n",
       "      <td>[-0.013982994481921196, 0.022177550941705704, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MR123459</td>\n",
       "      <td>{\\n  \"id\": \"MR123459\",\\n  \"equipmentId\": 1540,...</td>\n",
       "      <td>[-0.028072549030184746, 0.02523903176188469, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MR123472</td>\n",
       "      <td>{\\n  \"id\": \"MR123472\",\\n  \"equipmentId\": 534,\\...</td>\n",
       "      <td>[-0.018862921744585037, 0.008050049655139446, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MR123486</td>\n",
       "      <td>{\\n  \"id\": \"MR123486\",\\n  \"equipmentId\": 917,\\...</td>\n",
       "      <td>[-0.018444092944264412, 0.020266413688659668, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MR123458</td>\n",
       "      <td>{\\n  \"id\": \"MR123458\",\\n  \"equipmentId\": 514,\\...</td>\n",
       "      <td>[-0.00962898600846529, 0.011362914927303791, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MR123493</td>\n",
       "      <td>{\\n  \"id\": \"MR123493\",\\n  \"equipmentId\": 1538,...</td>\n",
       "      <td>[-0.015068135224282742, 0.013776778243482113, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MR123470</td>\n",
       "      <td>{\\n  \"id\": \"MR123470\",\\n  \"equipmentId\": 528,\\...</td>\n",
       "      <td>[-0.014766044914722443, 0.015853628516197205, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MR123466</td>\n",
       "      <td>{\\n  \"id\": \"MR123466\",\\n  \"equipmentId\": 534,\\...</td>\n",
       "      <td>[-0.020434923470020294, 0.008312629535794258, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MR123496</td>\n",
       "      <td>{\\n  \"id\": \"MR123496\",\\n  \"equipmentId\": 917,\\...</td>\n",
       "      <td>[-0.008990037254989147, 0.017453286796808243, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MR123457</td>\n",
       "      <td>{\\n  \"id\": \"MR123457\",\\n  \"equipmentId\": 536,\\...</td>\n",
       "      <td>[-0.0118974968791008, 0.020322881639003754, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MR123456</td>\n",
       "      <td>{\\n  \"id\": \"MR123456\",\\n  \"equipmentId\": 528,\\...</td>\n",
       "      <td>[-0.018081363290548325, 0.010219598188996315, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MR123481</td>\n",
       "      <td>{\\n  \"id\": \"MR123481\",\\n  \"equipmentId\": 3348,...</td>\n",
       "      <td>[-0.019523009657859802, 0.007061217445880175, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MR123492</td>\n",
       "      <td>{\\n  \"id\": \"MR123492\",\\n  \"equipmentId\": 6808,...</td>\n",
       "      <td>[-0.02487773448228836, 0.03101968951523304, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MR123487</td>\n",
       "      <td>{\\n  \"id\": \"MR123487\",\\n  \"equipmentId\": 917,\\...</td>\n",
       "      <td>[-0.003283120458945632, 0.025818848982453346, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MR123489</td>\n",
       "      <td>{\\n  \"id\": \"MR123489\",\\n  \"equipmentId\": 1563,...</td>\n",
       "      <td>[-0.020969154313206673, 0.027844060212373734, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MR123491</td>\n",
       "      <td>{\\n  \"id\": \"MR123491\",\\n  \"equipmentId\": 1498,...</td>\n",
       "      <td>[-0.01616201177239418, 0.025758204981684685, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MR123497</td>\n",
       "      <td>{\\n  \"id\": \"MR123497\",\\n  \"equipmentId\": 1563,...</td>\n",
       "      <td>[-0.018444161862134933, 0.031084412708878517, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MR123467</td>\n",
       "      <td>{\\n  \"id\": \"MR123467\",\\n  \"equipmentId\": 536,\\...</td>\n",
       "      <td>[-0.018159152939915657, 0.014184696599841118, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MR123461</td>\n",
       "      <td>{\\n  \"id\": \"MR123461\",\\n  \"equipmentId\": 2665,...</td>\n",
       "      <td>[-0.022699303925037384, 0.01569691300392151, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MR123460</td>\n",
       "      <td>{\\n  \"id\": \"MR123460\",\\n  \"equipmentId\": 585,\\...</td>\n",
       "      <td>[-0.022052135318517685, 0.004048418253660202, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MR123476</td>\n",
       "      <td>{\\n  \"id\": \"MR123476\",\\n  \"equipmentId\": 917,\\...</td>\n",
       "      <td>[-0.017977172508835793, 0.012858176603913307, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MR123471</td>\n",
       "      <td>{\\n  \"id\": \"MR123471\",\\n  \"equipmentId\": 534,\\...</td>\n",
       "      <td>[-0.035162024199962616, 0.006526491139084101, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>MR123484</td>\n",
       "      <td>{\\n  \"id\": \"MR123484\",\\n  \"equipmentId\": 2822,...</td>\n",
       "      <td>[-0.014447738416492939, 0.01580478437244892, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MR123499</td>\n",
       "      <td>{\\n  \"id\": \"MR123499\",\\n  \"equipmentId\": 1134,...</td>\n",
       "      <td>[-0.022939378395676613, 0.029363524168729782, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>MR123477</td>\n",
       "      <td>{\\n  \"id\": \"MR123477\",\\n  \"equipmentId\": 2822,...</td>\n",
       "      <td>[-0.007647366262972355, 0.01640325039625168, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MR123478</td>\n",
       "      <td>{\\n  \"id\": \"MR123478\",\\n  \"equipmentId\": 2666,...</td>\n",
       "      <td>[-0.013953953981399536, 0.005004465114325285, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>MR123488</td>\n",
       "      <td>{\\n  \"id\": \"MR123488\",\\n  \"equipmentId\": 1500,...</td>\n",
       "      <td>[-0.020427199080586433, 0.018171433359384537, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>MR123468</td>\n",
       "      <td>{\\n  \"id\": \"MR123468\",\\n  \"equipmentId\": 585,\\...</td>\n",
       "      <td>[-0.02139914594590664, 0.0035335849970579147, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T04:46:36.428434Z",
     "start_time": "2025-06-26T04:46:34.823452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#load\n",
    "for chunk in chunks(maintenance_record_emb_df[['id', 'embedding']].to_dict(orient='records')):\n",
    "    records = driver.execute_query(\n",
    "        \"\"\"\n",
    "        UNWIND $records AS rec\n",
    "        MATCH(n:MaintenanceRecord {id:rec.id})\n",
    "        CALL db.create.setNodeVectorProperty(n, 'embedding', rec.embedding)\n",
    "        RETURN count(rec) AS embeddings_upserted\n",
    "        \"\"\",\n",
    "        routing_=RoutingControl.WRITE,\n",
    "        result_transformer_= lambda r: r.data(),\n",
    "        records = chunk\n",
    "    )\n",
    "    print(records)\n",
    "\n",
    "# vector index\n",
    "driver.execute_query('''\n",
    "CREATE VECTOR INDEX text_embeddings IF NOT EXISTS FOR (n:MaintenanceRecord) ON (n.embedding)\n",
    "OPTIONS {indexConfig: {\n",
    " `vector.dimensions`: toInteger($dimension),\n",
    " `vector.similarity_function`: 'cosine'\n",
    "}}\n",
    "''', dimension=len(maintenance_record_emb_df[\"embedding\"][0]))\n",
    "\n",
    "# wait for index to come online\n",
    "driver.execute_query('CALL db.awaitIndex(\"text_embeddings\", 300)')"
   ],
   "id": "a9f0bd2a935e5ee8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'embeddings_upserted': 30}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EagerResult(records=[], summary=<neo4j._work.summary.ResultSummary object at 0x138748450>, keys=[])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
